{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import (\n",
    "    DebertaV2PreTrainedModel,\n",
    "    DebertaV2Model,\n",
    "    SequenceClassifierOutput,\n",
    ")\n",
    "from transformers import AutoModel, PretrainedConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from transformers import DebertaV2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TEST_CSV = \"../data/test.csv\"\n",
    "    TEST_CSV = \"../data/train.csv\"\n",
    "    SUB_CSV = \"../data/sample_submission.csv\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_name = \"llm-blender/PairRM-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CFG.TEST_CSV)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(s):\n",
    "    try:\n",
    "        return json.loads(s.replace(\"null\", '\"\"'))\n",
    "    except (ValueError, SyntaxError, json.JSONDecodeError):\n",
    "        # If parsing fails, return the input itself if it's already a list or return an empty list\n",
    "        if isinstance(s, list):\n",
    "            return s\n",
    "        elif isinstance(s, int):\n",
    "            return [str(s)]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "\n",
    "# Convert each element to string before joining\n",
    "def join_elements(elements):\n",
    "    return \" \".join(map(str, elements))\n",
    "\n",
    "\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: join_elements(safe_eval(x)))\n",
    "df[\"response_a\"] = df.response_a.map(\n",
    "    lambda x: join_elements(safe_eval(x.replace(\"null\", \"''\")))\n",
    ")\n",
    "df[\"response_b\"] = df.response_b.map(\n",
    "    lambda x: join_elements(safe_eval(x.replace(\"null\", \"''\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(row):\n",
    "    prompt = row.prompt.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
    "    response_a = row.response_a.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
    "    response_b = row.response_b.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
    "    row[\"left\"] = f\"<|source|> {prompt}\\n\\n\\n\\n <|candidate|> {response_a}\"\n",
    "    row[\"right\"] = f\"<|source|> {prompt}\\n\\n\\n\\n <|candidate|> {response_b}\"\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(make_pairs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "      <td>&lt;|source|&gt; I have three oranges today, I ate a...</td>\n",
       "      <td>&lt;|source|&gt; I have three oranges today, I ate a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "      <td>&lt;|source|&gt; You are a mediator in a heated poli...</td>\n",
       "      <td>&lt;|source|&gt; You are a mediator in a heated poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>How to initialize the classification head when...</td>\n",
       "      <td>When you want to initialize the classification...</td>\n",
       "      <td>To initialize the classification head when per...</td>\n",
       "      <td>&lt;|source|&gt; How to initialize the classificatio...</td>\n",
       "      <td>&lt;|source|&gt; How to initialize the classificatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  I have three oranges today, I ate an orange ye...   \n",
       "1   211333  You are a mediator in a heated political debat...   \n",
       "2  1233961  How to initialize the classification head when...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                        You have two oranges today.   \n",
       "1  Thank you for sharing the details of the situa...   \n",
       "2  When you want to initialize the classification...   \n",
       "\n",
       "                                          response_b  \\\n",
       "0  You still have three oranges. Eating an orange...   \n",
       "1  Mr Reddy and Ms Blue both have valid points in...   \n",
       "2  To initialize the classification head when per...   \n",
       "\n",
       "                                                left  \\\n",
       "0  <|source|> I have three oranges today, I ate a...   \n",
       "1  <|source|> You are a mediator in a heated poli...   \n",
       "2  <|source|> How to initialize the classificatio...   \n",
       "\n",
       "                                               right  \n",
       "0  <|source|> I have three oranges today, I ate a...  \n",
       "1  <|source|> You are a mediator in a heated poli...  \n",
       "2  <|source|> How to initialize the classificatio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, left, right, tokenizer, max_length):\n",
    "        self.ids = ids\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def get_encoded(self, text):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        padding_lenght = self.max_length - len(ids)\n",
    "\n",
    "        ids = ids + ([0] * padding_lenght)\n",
    "        mask = mask + ([0] * padding_lenght)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_lenght)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        left = self.left[idx]\n",
    "        right = self.right[idx]\n",
    "        ids = self.ids[idx]\n",
    "\n",
    "        return {\n",
    "            \"left\": self.get_encoded(left),\n",
    "            \"right\": self.get_encoded(right),\n",
    "            \"ids\": ids,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        default_deberta_config = {\n",
    "            \"model_type\": \"deberta-v2\",\n",
    "            \"attention_probs_dropout_prob\": 0.1,\n",
    "            \"hidden_act\": \"gelu\",\n",
    "            \"hidden_dropout_prob\": 0.1,\n",
    "            \"hidden_size\": 1024,\n",
    "            \"initializer_range\": 0.02,\n",
    "            \"intermediate_size\": 4096,\n",
    "            \"max_position_embeddings\": 512,\n",
    "            \"relative_attention\": True,\n",
    "            \"position_buckets\": 256,\n",
    "            \"norm_rel_ebd\": \"layer_norm\",\n",
    "            \"share_att_key\": True,\n",
    "            \"pos_att_type\": \"p2c|c2p\",\n",
    "            \"layer_norm_eps\": 1e-7,\n",
    "            \"max_relative_positions\": -1,\n",
    "            \"position_biased_input\": True,\n",
    "            \"num_attention_heads\": 16,\n",
    "            \"num_hidden_layers\": 24,\n",
    "            \"type_vocab_size\": 0,\n",
    "            \"vocab_size\": 128005,\n",
    "            \"n_tasks\": 1,\n",
    "            \"drop_out\": 0,\n",
    "            \"sep_token_id\": 2,\n",
    "            \"source_prefix_id\": 0,\n",
    "            \"cand_prefix_id\": 3,\n",
    "            \"cand1_prefix_id\": 3,\n",
    "            \"cand2_prefix_id\": 4,\n",
    "        }\n",
    "        config = PretrainedConfig.from_dict(default_deberta_config)\n",
    "        self.backbone = DebertaV2Model(config=config)\n",
    "\n",
    "        # get the hidden size of the transformer\n",
    "        self.hidden_size = self.backbone.config.hidden_size\n",
    "\n",
    "        self.head_layer = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0),\n",
    "            torch.nn.Linear(2 * self.hidden_size, 1 * self.hidden_size),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Dropout(0),\n",
    "            torch.nn.Linear(1 * self.hidden_size, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, left, right):\n",
    "        l_pooled_output = self.backbone(\n",
    "            left[\"input_ids\"],\n",
    "            attention_mask=left[\"attention_mask\"].cuda(),\n",
    "            token_type_ids=left[\"token_type_ids\"].cuda(),\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "        r_pooled_output = self.backbone(\n",
    "            right[\"input_ids\"],\n",
    "            attention_mask=right[\"attention_mask\"].cuda(),\n",
    "            token_type_ids=right[\"token_type_ids\"].cuda(),\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "        embeds = torch.cat((l_pooled_output[0], r_pooled_output[0]), dim=-1)\n",
    "        embeds = torch.mean(embeds, dim=1).type(torch.float32)\n",
    "\n",
    "        output = self.head_layer(embeds)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(3).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['backbone.embeddings.position_embeddings.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load microsoft/deberta-v3-large without loading weights\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"../logs/20240628-010538-backend-None-lr-1e-06/model.pth\"),\n",
    "    strict=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "\n",
    "# save tokenizer\n",
    "tokenizer.save_pretrained(\"../models/pairrm-hf-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TransformerDataset(\n",
    "    df[\"id\"].to_list(),\n",
    "    df[\"left\"].to_list(),\n",
    "    df[\"right\"].to_list(),\n",
    "    tokenizer,\n",
    "    512,\n",
    ")\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=16, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader_train:\n",
    "    ids = batch[\"ids\"]\n",
    "    left = batch[\"left\"]\n",
    "    right = batch[\"right\"]\n",
    "    output = model(\n",
    "        {\n",
    "            \"input_ids\": batch[\"left\"][\"input_ids\"].to(CFG.device),\n",
    "            \"attention_mask\": batch[\"left\"][\"attention_mask\"].to(CFG.device),\n",
    "            \"token_type_ids\": batch[\"left\"][\"token_type_ids\"].to(CFG.device),\n",
    "        },\n",
    "        {\n",
    "            \"input_ids\": batch[\"right\"][\"input_ids\"].to(CFG.device),\n",
    "            \"attention_mask\": batch[\"right\"][\"attention_mask\"].to(CFG.device),\n",
    "            \"token_type_ids\": batch[\"right\"][\"token_type_ids\"].to(CFG.device),\n",
    "        },\n",
    "    )\n",
    "    output = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    for i, o in zip(ids, output):\n",
    "        outputs.append([i.item(), o[0].item(), o[1].item(), o[2].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[136060, 0.012044858187437057, 0.8154296875, 0.17252545058727264],\n",
       " [211333, 0.00034956890158355236, 0.023133503273129463, 0.976516842842102],\n",
       " [1233961, 0.9975916147232056, 2.8982574804103933e-05, 0.002379420679062605]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(CFG.SUB_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all rows\n",
    "submit_df.drop(submit_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, winner_model_a, winner_model_b, winner_tie]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the outputs into the submit_df\n",
    "submit_df = pd.DataFrame(outputs, columns=submit_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.012045</td>\n",
       "      <td>0.815430</td>\n",
       "      <td>0.172525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>0.976517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.997592</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.012045        0.815430    0.172525\n",
       "1   211333        0.000350        0.023134    0.976517\n",
       "2  1233961        0.997592        0.000029    0.002379"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
